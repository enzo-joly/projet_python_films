{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6aef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import threading\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "API_KEY = \"1d48b5e24b27cd111582c21dcff9b8f5\"\n",
    "BASE_URL = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "thread_local = threading.local()\n",
    "\n",
    "def get_session():\n",
    "    \"\"\"\n",
    "    Renvoie la session unique dédiée au thread qui appelle cette fonction.\n",
    "    \"\"\"\n",
    "    if not hasattr(thread_local, \"session\"):\n",
    "        thread_local.session = requests.Session()\n",
    "        \n",
    "        # --- 3. L'ADAPTER (Tuning) ---\n",
    "        # On configure le moteur pour être robuste\n",
    "        adapter = HTTPAdapter(\n",
    "            pool_connections=10,  # Nombre de site web\n",
    "            pool_maxsize=10,      # Taille max du pool = max worker\n",
    "            max_retries=3         # Réessaie 3 fois si échec de connexion pure\n",
    "        )\n",
    "        \n",
    "        # On installe ce moteur pour toutes les requêtes\n",
    "        thread_local.session.mount('https://', adapter)\n",
    "        thread_local.session.mount('http://', adapter)\n",
    "\n",
    "    return thread_local.session\n",
    "\n",
    "def get_json(url, params=None, max_retries=3, delay=2):\n",
    "    \"\"\"A function to make get requests and return a json file, with a retry function\"\"\"\n",
    "\n",
    "    params = params or {}\n",
    "    params['api_key'] = API_KEY\n",
    "\n",
    "    session = get_session()\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = session.get(url, params=params, timeout=10)\n",
    "            \n",
    "            # Si on dépasse le quota (429), on attend et on réessaie\n",
    "            if response.status_code == 429:\n",
    "                print(f\"Rate limit atteint. Pause de {delay}s...\")\n",
    "                time.sleep(delay)\n",
    "                continue # On passe à l'itération suivante de la boucle for (nouvel essai)\n",
    "            \n",
    "            response.raise_for_status() # Lève une exception pour les codes 4xx/5xx\n",
    "            return response.json()\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Erreur API : {e}\")\n",
    "            if attempt+1 < max_retries :\n",
    "                time.sleep(delay) # Attente avant le prochain essai\n",
    "            else:\n",
    "                return None # Abandon après max_retries\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_tmdb_id(imdb_id):\n",
    "    \"\"\"A funtion to get TMBD id from IMDb id\"\"\"\n",
    "\n",
    "    json_file = get_json(f\"{BASE_URL}/find/{imdb_id}\", {\"external_source\" : \"imdb_id\"})\n",
    "\n",
    "    if json_file == None : # Return None if API Error\n",
    "        return None\n",
    "    \n",
    "    results = json_file.get('movie_results', [])\n",
    "    if len(results) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return results[0]['id']\n",
    "\n",
    "def get_movie_details(movie_id):\n",
    "    \"\"\"A function to get detailed movie info by movie ID\"\"\"\n",
    "\n",
    "    details = get_json(f\"{BASE_URL}/movie/{movie_id}\", {\"append_to_response\": \"credits\"})\n",
    "\n",
    "    if details != None : \n",
    "\n",
    "        return {\n",
    "            \"tmdb_id\" : movie_id,\n",
    "            \"imdb_id\" : details.get(\"imdb_id\"),\n",
    "            \"original_language\" : details.get(\"original_language\"),\n",
    "            \"popularity\" : details.get(\"popularity\"),\n",
    "            \"overview\" : details.get(\"overview\"), \n",
    "            \"budget\" : details.get(\"budget\"),\n",
    "            \"country\": details.get(\"origin_country\"),\n",
    "            \"production_companies\" : [c[\"name\"] for c in details.get(\"production_companies\", [])] if details.get(\"production_companies\") else [],\n",
    "            \"revenue\" : details.get(\"revenue\"),\n",
    "            \"vote_average\" : details.get(\"vote_average\"),\n",
    "            \"vote_count\" : details.get(\"vote_count\"),\n",
    "            \"cast\": [{\"name\": c[\"name\"], \"gender\": c[\"gender\"], \"pop\": c[\"popularity\"]} for c in details.get(\"credits\", {}).get(\"cast\",[])[:10]] if details.get(\"credits\", {}).get(\"cast\") else {} # main 10 actors\n",
    "        }\n",
    "    else : # If API Error\n",
    "        return None\n",
    "\n",
    "def fetch_full_movie_data(imdb_id):\n",
    "    \"\"\"Fonction maître\"\"\"\n",
    "    \n",
    "    tmdb_id = get_tmdb_id(imdb_id)\n",
    "\n",
    "    if tmdb_id is None:\n",
    "        return {\"status\": \"api_error\", \"imdb_id\": imdb_id, \"data\": None}\n",
    "    elif tmdb_id == 0:\n",
    "        return {\"status\": \"not_found\", \"imdb_id\": imdb_id, \"data\": None}\n",
    "    else:\n",
    "        details = get_movie_details(tmdb_id)\n",
    "        if details:\n",
    "            return {\"status\": \"success\", \"imdb_id\": imdb_id, \"data\": details}\n",
    "        else:\n",
    "            return {\"status\": \"api_error_details\", \"imdb_id\": imdb_id, \"data\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb559db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement ultra-rapide du Parquet...\n",
      "Prêt ! 265654 films chargés.\n"
     ]
    }
   ],
   "source": [
    "#Importation de la liste de IMDB ID \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "chemin_parquet = 'IMDB_movie_ratings.parquet'\n",
    "\n",
    "try:\n",
    "    print(\"Chargement ultra-rapide du Parquet...\")\n",
    "    df_source = pd.read_parquet(chemin_parquet, engine='pyarrow')\n",
    "    \n",
    "    # Extraction de la liste des IDs\n",
    "    imdb_id_list = df_source['tconst'].unique().tolist()\n",
    "    \n",
    "    print(f\"Prêt ! {len(imdb_id_list)} films chargés.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Fichier introuvable. Lance le script de préparation d'abord.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e87e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du traitement : 265654 films répartis en 89 paquets.\n",
      "--- Traitement du paquet 1/89 ---\n",
      "   -> Sauvegardé tmdb_results/success/data_0000.parquet (2853 lignes)\n",
      "   -> Sauvegardé tmdb_results/not_found/notfound_0000.parquet (147 lignes)\n",
      "--- Traitement du paquet 2/89 ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n",
    "import time\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "OUTPUT_DIR_SUCCESS = \"tmdb_results/success\"\n",
    "OUTPUT_DIR_NOTFOUND = \"tmdb_results/not_found\"\n",
    "OUTPUT_DIR_ERRORS = \"tmdb_results/errors\"\n",
    "\n",
    "# Création des 3 dossiers\n",
    "os.makedirs(OUTPUT_DIR_SUCCESS, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_NOTFOUND, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_ERRORS, exist_ok=True)\n",
    "\n",
    "def save_batch(data_list, folder, prefix, batch_idx):\n",
    "    \"\"\"Fonction utilitaire pour sauvegarder une liste si elle n'est pas vide.\"\"\"\n",
    "    if data_list:\n",
    "        df = pd.DataFrame(data_list)\n",
    "\n",
    "        # --- BLOC DE SÉCURISATION ---\n",
    "        # On identifie les colonnes qui contiennent des listes ou des objets complexes et on les convertit en chaîne de caractères JSON.\n",
    "        complex_cols = [\"cast\", \"production_companies\"]\n",
    "        \n",
    "        for col in complex_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str)\n",
    "        # ----------------------------\n",
    "\n",
    "        filename = os.path.join(folder, f\"{prefix}_{batch_idx:04d}.parquet\")\n",
    "        df.to_parquet(filename, engine='pyarrow')\n",
    "        print(f\"   -> Sauvegardé {filename} ({len(df)} lignes)\")\n",
    "\n",
    "def process_in_batches(full_id_list, batch_size=1000, max_workers=10):\n",
    "    \"\"\"\n",
    "    Traite la liste de films par paquet\n",
    "    \"\"\"\n",
    "    total_processed = 0\n",
    "    total_films = len(full_id_list)\n",
    "\n",
    "    # On découpe la liste géante en petits morceaux (chunks)\n",
    "    # Ex: liste[0:1000], puis liste[1000:2000]...\n",
    "    chunks = [full_id_list[i:i + batch_size] for i in range(0, total_films, batch_size)]\n",
    "\n",
    "    print(f\"Début du traitement : {total_films} films répartis en {len(chunks)} paquets.\")\n",
    "\n",
    "    for chunk_index, chunk in enumerate(chunks):\n",
    "        print(f\"--- Traitement du paquet {chunk_index + 1}/{len(chunks)} ---\")\n",
    "        \n",
    "        # 3 Buffers temporaires pour ce paquet\n",
    "        batch_success = []\n",
    "        batch_notfound = []\n",
    "        batch_errors = []\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            \n",
    "            # Ici, on ne crée que 'batch_size' (ex: 1000) futures. C'est safe pour la RAM.\n",
    "            future_to_imdb = {executor.submit(fetch_full_movie_data, mid): mid for mid in chunk}\n",
    "            \n",
    "            for future in as_completed(future_to_imdb):\n",
    "                imdb_id = future_to_imdb[future]\n",
    "                try:\n",
    "                    # C'est ici qu'on récupère le résultat.\n",
    "                    # Si fetch_full_movie_data a crashé (bug imprévu), ça saute au 'except'.\n",
    "                    result = future.result() \n",
    "\n",
    "                    # TRI DES RÉSULTATS\n",
    "                    if result[\"status\"] == \"success\":\n",
    "                        batch_success.append(result[\"data\"])\n",
    "                    \n",
    "                    elif result[\"status\"] == \"not_found\":\n",
    "                        batch_notfound.append({\"imdb_id\": result[\"imdb_id\"]})\n",
    "                    \n",
    "                    else: # api_error\n",
    "                        batch_errors.append({\"imdb_id\": result[\"imdb_id\"], \"reason\": result.get(\"reason\")})\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"CRITICAL WORKER CRASH sur {imdb_id}: {e}\")\n",
    "                    batch_errors.append({\"imdb_id\": imdb_id, \"reason\": f\"system_crash: {str(e)}\"})\n",
    "\n",
    "        # À la fin du paquet, on sauvegarde immédiatement\n",
    "        save_batch(batch_success, OUTPUT_DIR_SUCCESS, \"data\", chunk_index)\n",
    "        save_batch(batch_notfound, OUTPUT_DIR_NOTFOUND, \"notfound\", chunk_index)\n",
    "        save_batch(batch_errors, OUTPUT_DIR_ERRORS, \"errors\", chunk_index)\n",
    "        \n",
    "        # Nettoyage explicite\n",
    "        del batch_success, batch_notfound, batch_errors\n",
    "\n",
    "\n",
    "# --- EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Supposons que c'est la liste à parcourir\n",
    "    #imdb_id_list = [\"tt0133093\", \"tt0137523\", \"tt0068646\", \"tt_ID_FOIREUX\"] * 3000  \n",
    "    \n",
    "    # On lance par paquets\n",
    "    process_in_batches(imdb_id_list, batch_size=3000, max_workers=10)\n",
    "\n",
    "print('Scraping terminé')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e67f2",
   "metadata": {},
   "source": [
    "39 sec pour 4000 films en 40 paquets, worker = 10, delay = 2\n",
    "\n",
    "27 sec pour 4000 films en 4 paquets, worker = 10, delay = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d1ca1",
   "metadata": {},
   "source": [
    "40 s pour 400 films en 4 paquts, worker = 20, delay = 2\n",
    "\n",
    "\n",
    "1 min 6 pour 400 films en 4 paquts, worker = 30, delay = 2\n",
    "\n",
    "28 s pour 400 films en 4 paquts, worker = 30, delay = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e02061",
   "metadata": {},
   "source": [
    "2 min 33 pour 2000 films en 20 batch (size = 100), delay = 2, et max worker = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac37116b",
   "metadata": {},
   "source": [
    "# Ouverture du fichier parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0e11dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données Parquet...\n",
      "Chargé : 13200 films.\n",
      "\n",
      "Conversion des colonnes textuelles en listes Python...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmdb_id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>popularity</th>\n",
       "      <th>overview</th>\n",
       "      <th>budget</th>\n",
       "      <th>country</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>revenue</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>cast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550</td>\n",
       "      <td>tt0137523</td>\n",
       "      <td>en</td>\n",
       "      <td>16.3002</td>\n",
       "      <td>A ticking-time-bomb insomniac and a slippery s...</td>\n",
       "      <td>63000000</td>\n",
       "      <td>[US]</td>\n",
       "      <td>[Fox 2000 Pictures, Regency Enterprises, Linso...</td>\n",
       "      <td>100853753</td>\n",
       "      <td>8.438</td>\n",
       "      <td>31053</td>\n",
       "      <td>[{'name': 'Edward Norton', 'gender': 2, 'pop':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238</td>\n",
       "      <td>tt0068646</td>\n",
       "      <td>en</td>\n",
       "      <td>25.1984</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "      <td>6000000</td>\n",
       "      <td>[US]</td>\n",
       "      <td>[Paramount Pictures, Alfran Productions]</td>\n",
       "      <td>245066411</td>\n",
       "      <td>8.684</td>\n",
       "      <td>22119</td>\n",
       "      <td>[{'name': 'Marlon Brando', 'gender': 2, 'pop':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550</td>\n",
       "      <td>tt0137523</td>\n",
       "      <td>en</td>\n",
       "      <td>16.3002</td>\n",
       "      <td>A ticking-time-bomb insomniac and a slippery s...</td>\n",
       "      <td>63000000</td>\n",
       "      <td>[US]</td>\n",
       "      <td>[Fox 2000 Pictures, Regency Enterprises, Linso...</td>\n",
       "      <td>100853753</td>\n",
       "      <td>8.438</td>\n",
       "      <td>31053</td>\n",
       "      <td>[{'name': 'Edward Norton', 'gender': 2, 'pop':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>603</td>\n",
       "      <td>tt0133093</td>\n",
       "      <td>en</td>\n",
       "      <td>18.0592</td>\n",
       "      <td>Set in the 22nd century, The Matrix tells the ...</td>\n",
       "      <td>63000000</td>\n",
       "      <td>[US]</td>\n",
       "      <td>[Village Roadshow Pictures, Groucho II Film Pa...</td>\n",
       "      <td>463517383</td>\n",
       "      <td>8.236</td>\n",
       "      <td>27048</td>\n",
       "      <td>[{'name': 'Keanu Reeves', 'gender': 2, 'pop': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>238</td>\n",
       "      <td>tt0068646</td>\n",
       "      <td>en</td>\n",
       "      <td>25.1984</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "      <td>6000000</td>\n",
       "      <td>[US]</td>\n",
       "      <td>[Paramount Pictures, Alfran Productions]</td>\n",
       "      <td>245066411</td>\n",
       "      <td>8.684</td>\n",
       "      <td>22119</td>\n",
       "      <td>[{'name': 'Marlon Brando', 'gender': 2, 'pop':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tmdb_id    imdb_id original_language  popularity  \\\n",
       "0      550  tt0137523                en     16.3002   \n",
       "1      238  tt0068646                en     25.1984   \n",
       "2      550  tt0137523                en     16.3002   \n",
       "3      603  tt0133093                en     18.0592   \n",
       "4      238  tt0068646                en     25.1984   \n",
       "\n",
       "                                            overview    budget country  \\\n",
       "0  A ticking-time-bomb insomniac and a slippery s...  63000000    [US]   \n",
       "1  Spanning the years 1945 to 1955, a chronicle o...   6000000    [US]   \n",
       "2  A ticking-time-bomb insomniac and a slippery s...  63000000    [US]   \n",
       "3  Set in the 22nd century, The Matrix tells the ...  63000000    [US]   \n",
       "4  Spanning the years 1945 to 1955, a chronicle o...   6000000    [US]   \n",
       "\n",
       "                                production_companies    revenue  vote_average  \\\n",
       "0  [Fox 2000 Pictures, Regency Enterprises, Linso...  100853753         8.438   \n",
       "1           [Paramount Pictures, Alfran Productions]  245066411         8.684   \n",
       "2  [Fox 2000 Pictures, Regency Enterprises, Linso...  100853753         8.438   \n",
       "3  [Village Roadshow Pictures, Groucho II Film Pa...  463517383         8.236   \n",
       "4           [Paramount Pictures, Alfran Productions]  245066411         8.684   \n",
       "\n",
       "   vote_count                                               cast  \n",
       "0       31053  [{'name': 'Edward Norton', 'gender': 2, 'pop':...  \n",
       "1       22119  [{'name': 'Marlon Brando', 'gender': 2, 'pop':...  \n",
       "2       31053  [{'name': 'Edward Norton', 'gender': 2, 'pop':...  \n",
       "3       27048  [{'name': 'Keanu Reeves', 'gender': 2, 'pop': ...  \n",
       "4       22119  [{'name': 'Marlon Brando', 'gender': 2, 'pop':...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast  # Bibliothèque standard (Abstract Syntax Tree)\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_FOLDER = \"tmdb_results/success\"  # Ton dossier contenant les fichiers .parquet\n",
    "\n",
    "# --- FONCTION UTILITAIRE DE CONVERSION ---\n",
    "def text_to_list(x):\n",
    "    \"\"\"\n",
    "    Tente de convertir une chaîne \"['a', 'b']\" en vraie liste ['a', 'b'].\n",
    "    Si c'est vide, None, ou une erreur, renvoie une liste vide [].\n",
    "    \"\"\"\n",
    "    # Si c'est déjà une liste, on renvoie tel quel\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    \n",
    "    # Si c'est un None ou un float (NaN), on renvoie une liste vide\n",
    "    if pd.isna(x) or x == \"None\" or x == \"\":\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        # La magie opère ici : évalue la structure Python contenue dans le texte\n",
    "        return ast.literal_eval(x)\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Si le texte est corrompu, on renvoie une liste vide par sécurité\n",
    "        return []\n",
    "\n",
    "# --- 1. CHARGEMENT DU DATAFRAME ---\n",
    "print(\"Chargement des données Parquet...\")\n",
    "\n",
    "# Pandas détecte que c'est un dossier et fusionne tout automatiquement\n",
    "df = pd.read_parquet(INPUT_FOLDER, engine='pyarrow')\n",
    "\n",
    "print(f\"Chargé : {len(df)} films.\")\n",
    "\n",
    "# --- 2. RECONSTRUCTION DES LISTES ---\n",
    "print(\"\\nConversion des colonnes textuelles en listes Python...\")\n",
    "\n",
    "# Liste des colonnes qu'on avait converties en texte à la sauvegarde\n",
    "cols_to_convert = [\"cast\", \"production_companies\"]\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    if col in df.columns:\n",
    "        # On applique la fonction ligne par ligne\n",
    "        df[col] = df[col].apply(text_to_list)\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
